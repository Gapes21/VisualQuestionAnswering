{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Todo\n\n- [ ] training loop\n- [ ] metrics computation\n- [ ] tensorboard/wandb","metadata":{}},{"cell_type":"code","source":"import datasets\nfrom transformers import AutoImageProcessor, AutoModel, AutoTokenizer\nfrom huggingface_hub import login\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\n\nimport math\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score, accuracy_score\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport os\n\nfrom dataclasses import dataclass","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:45:59.981597Z","iopub.execute_input":"2024-05-14T23:45:59.982338Z","iopub.status.idle":"2024-05-14T23:46:06.521562Z","shell.execute_reply.started":"2024-05-14T23:45:59.982307Z","shell.execute_reply":"2024-05-14T23:46:06.520686Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-14 23:46:03.821093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-14 23:46:03.821165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-14 23:46:03.822616: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"login(\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:06.523608Z","iopub.execute_input":"2024-05-14T23:46:06.524802Z","iopub.status.idle":"2024-05-14T23:46:06.894325Z","shell.execute_reply.started":"2024-05-14T23:46:06.524761Z","shell.execute_reply":"2024-05-14T23:46:06.893417Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:06.895344Z","iopub.execute_input":"2024-05-14T23:46:06.895649Z","iopub.status.idle":"2024-05-14T23:46:06.938173Z","shell.execute_reply.started":"2024-05-14T23:46:06.895624Z","shell.execute_reply":"2024-05-14T23:46:06.937230Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"dataset = datasets.load_dataset(\"Gapes21/vqa2\", split = \"train\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:06.940249Z","iopub.execute_input":"2024-05-14T23:46:06.940621Z","iopub.status.idle":"2024-05-14T23:46:09.032954Z","shell.execute_reply.started":"2024-05-14T23:46:06.940583Z","shell.execute_reply":"2024-05-14T23:46:09.032225Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"labelEncoder = LabelEncoder()\nlabelEncoder.fit(dataset['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.034485Z","iopub.execute_input":"2024-05-14T23:46:09.034930Z","iopub.status.idle":"2024-05-14T23:46:09.348659Z","shell.execute_reply.started":"2024-05-14T23:46:09.034896Z","shell.execute_reply":"2024-05-14T23:46:09.346764Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"BERT = \"FacebookAI/roberta-base\"\nVIT = 'facebook/dinov2-base'","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.350095Z","iopub.execute_input":"2024-05-14T23:46:09.350434Z","iopub.status.idle":"2024-05-14T23:46:09.356275Z","shell.execute_reply.started":"2024-05-14T23:46:09.350405Z","shell.execute_reply":"2024-05-14T23:46:09.354955Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(VIT)\ntokenizer = AutoTokenizer.from_pretrained(BERT)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.357951Z","iopub.execute_input":"2024-05-14T23:46:09.358658Z","iopub.status.idle":"2024-05-14T23:46:09.698070Z","shell.execute_reply.started":"2024-05-14T23:46:09.358625Z","shell.execute_reply":"2024-05-14T23:46:09.697011Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SastaLoader:\n    def __init__(self, dataset, batch_size, collator_fn, train_max = 100000, mode = \"train\"):\n        self.dataset = dataset.shuffle()\n        self.collator_fn = collator_fn\n        self.len = len(self.dataset)\n        self.batch_size = batch_size\n        if mode == \"train\":\n            self.index = 0\n        else :\n            self.index = train_max\n        self.train_max = train_max\n        self.mode = mode\n\n    def hasNext(self):\n        if self.mode == \"train\":\n            return self.index + self.batch_size <= self.train_max\n        else :\n            return self.index + self.batch.size <= self.len\n    \n    def reset(self):\n        if self.mode == \"train\":\n            self.index = 0\n        else:\n            self.index = self.train_max\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.mode == \"train\":\n            if self.index >= self.train_max:\n                raise StopIteration\n        else :\n            if self.index >= self.len:\n                raise StopIteration\n                \n        batch = self.dataset[self.index: self.index + self.batch_size]\n        batch = self.collator_fn(batch)\n        self.index += self.batch_size\n        return batch\n    \n    def __len__(self):\n        if self.mode == \"train\":\n            return self.train_max\n        return self.len - self.train_max\n    \n    def train(self):\n        self.mode = \"train\"\n        \n    def validate(self):\n        self.mode = \"validation\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.699349Z","iopub.execute_input":"2024-05-14T23:46:09.699839Z","iopub.status.idle":"2024-05-14T23:46:09.712656Z","shell.execute_reply.started":"2024-05-14T23:46:09.699784Z","shell.execute_reply":"2024-05-14T23:46:09.711535Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def sasta_collator(batch):\n    # process images\n    images = processor(images = batch['image'], return_tensors=\"pt\")['pixel_values']\n\n    # preprocess questions\n    questions = tokenizer(\n            text=batch['question'],\n            padding='longest',\n            max_length=24,\n            truncation=True,\n            return_tensors='pt',\n            return_attention_mask=True,\n        )\n\n    # process labels\n    labels = torch.Tensor(labelEncoder.transform(batch['answer']))\n\n    return (images, questions, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.714084Z","iopub.execute_input":"2024-05-14T23:46:09.714534Z","iopub.status.idle":"2024-05-14T23:46:09.726111Z","shell.execute_reply.started":"2024-05-14T23:46:09.714503Z","shell.execute_reply":"2024-05-14T23:46:09.725254Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class VQAModel(nn.Module):\n    def __init__(\n        self,\n        num_labels,\n        intermediate_dim,\n        pretrained_text_name,\n        pretrained_image_name\n    ):\n        super(VQAModel, self).__init__()\n        \n        self.num_labels = num_labels\n        self.intermediate_dim = intermediate_dim\n        self.pretrained_text_name = pretrained_text_name\n        self.pretrained_image_name = pretrained_image_name\n        \n        # Text and image encoders\n        \n        self.text_encoder = AutoModel.from_pretrained(self.pretrained_text_name)\n        self.image_encoder = AutoModel.from_pretrained(self.pretrained_image_name)\n\n        assert(self.text_encoder.config.hidden_size == self.image_encoder.config.hidden_size)\n\n        self.embedd_dim = self.text_encoder.config.hidden_size\n\n        # Co-attentions\n        self.textq = nn.MultiheadAttention(self.embedd_dim, 1, 0.1, batch_first=True)\n        self.imgq = nn.MultiheadAttention(self.embedd_dim, 1, 0.1, batch_first=True)\n        \n        # Classifier\n        self.classifier = nn.Linear(self.embedd_dim, self.num_labels)\n\n    def forward(\n        self,\n        input_ids,\n        pixel_values,\n        attention_mask\n    ):\n        # Encode text with masking\n        encoded_text = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        \n        # Encode images\n        encoded_image = self.image_encoder(\n            pixel_values=pixel_values,\n        )\n        \n        text = encoded_text.last_hidden_state\n        img = encoded_image.last_hidden_state\n\n        textcls = self.textq(text, img, img)[0][:, 0, :]\n        imgcls = self.imgq(img, text, text)[0][:, 0, :]\n\n        cls = textcls+imgcls\n        \n        # Make predictions\n        logits = self.classifier(cls)\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.729992Z","iopub.execute_input":"2024-05-14T23:46:09.730369Z","iopub.status.idle":"2024-05-14T23:46:09.742606Z","shell.execute_reply.started":"2024-05-14T23:46:09.730337Z","shell.execute_reply":"2024-05-14T23:46:09.741528Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"#### Model, optimizer and loss","metadata":{}},{"cell_type":"code","source":"def save_model(model, name):\n    torch.save(model.state_dict(), name)\n\ndef initVQA():\n    model = VQAModel(len(labelEncoder.classes_), 512, BERT, VIT).to(device)\n    return model\n\ndef load_model(name, backup = initVQA):\n    model = backup()\n    try : \n        model.load_state_dict(torch.load(f\"/kaggle/working/{name}\"))\n        print(\"Loaded model successfully.\")\n    except:\n        print(\"Couldn't find model. Initializing from scratch.\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:46:09.744285Z","iopub.execute_input":"2024-05-14T23:46:09.744743Z","iopub.status.idle":"2024-05-14T23:46:09.755493Z","shell.execute_reply.started":"2024-05-14T23:46:09.744706Z","shell.execute_reply":"2024-05-14T23:46:09.754520Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"vqa_dr.pth\")\noptimizer = optim.Adam(model.parameters(), lr=0.05)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T00:59:34.915109Z","iopub.execute_input":"2024-05-15T00:59:34.915541Z","iopub.status.idle":"2024-05-15T00:59:36.403036Z","shell.execute_reply.started":"2024-05-15T00:59:34.915508Z","shell.execute_reply":"2024-05-15T00:59:36.402042Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loaded model successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Hyperparams","metadata":{}},{"cell_type":"code","source":"collator_fn = sasta_collator\nloader = SastaLoader(dataset, 16, sasta_collator)\nnum_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2024-05-15T00:59:42.810321Z","iopub.execute_input":"2024-05-15T00:59:42.810689Z","iopub.status.idle":"2024-05-15T00:59:42.872203Z","shell.execute_reply.started":"2024-05-15T00:59:42.810662Z","shell.execute_reply":"2024-05-15T00:59:42.871372Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, criterion, loader, num_epochs, device):\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n    loss_plot, accuracy_plot = [], []\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        correct = 0\n        total_samples = 0\n        with tqdm(total=len(loader), desc=\"Processing batches\", dynamic_ncols=True) as pbar:\n            for batchidx, batch in enumerate(loader):\n                ids = batch[1]['input_ids'].to(device)\n                pxlvalues = batch[0].to(device)\n                masks = batch[1]['attention_mask'].to(device)\n                labels = batch[2].to(device)\n\n                optimizer.zero_grad()\n                outputs = model(ids, pxlvalues, masks)\n                loss = criterion(outputs, labels.long())\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item() * loader.batch_size\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n                pbar.update(loader.batch_size)\n                if batchidx % 16000 <= 1:\n                    save_model(model, 'vqa_dr.pth')\n                \n        epoch_loss = total_loss / total_samples\n        accuracy = correct / total_samples\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n        accuracy_plot.append(accuracy * 100)\n        loss_plot.append(epoch_loss)\n        save_model(model, \"vqa_dr.pth\")\n        scheduler.step()\n        loader.reset()\n    plt.plot(accuracy_plot)\n    plt.plot(loss_plot)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T23:50:07.301411Z","iopub.execute_input":"2024-05-14T23:50:07.302179Z","iopub.status.idle":"2024-05-14T23:50:07.313766Z","shell.execute_reply.started":"2024-05-14T23:50:07.302150Z","shell.execute_reply":"2024-05-14T23:50:07.312750Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train(model, optimizer, criterion, loader, num_epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T01:07:04.387388Z","iopub.execute_input":"2024-05-15T01:07:04.388387Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Processing batches:  45%|████▍     | 44976/100000 [28:53<35:10, 26.07it/s] ","output_type":"stream"}]},{"cell_type":"code","source":"validation_loader = SastaLoader(dataset, 16, sasta_collator, mode = \"validation\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T00:54:29.967867Z","iopub.execute_input":"2024-05-15T00:54:29.968795Z","iopub.status.idle":"2024-05-15T00:54:30.030917Z","shell.execute_reply.started":"2024-05-15T00:54:29.968759Z","shell.execute_reply":"2024-05-15T00:54:30.029980Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, loader, device):\n    y_true, y_pred = [], []\n    model.eval()\n    loader.reset()\n    with tqdm(total=len(loader), desc=\"Processing batches\", dynamic_ncols=True) as pbar:\n        for batchidx, batch in enumerate(loader):\n            ids = batch[1]['input_ids'].to(device)\n            pxlvalues = batch[0].to(device)\n            masks = batch[1]['attention_mask'].to(device)\n            labels = batch[2].to(\"cpu\")\n            outputs = model(ids, pxlvalues, masks)\n            _, predicted = torch.max(outputs, 1)\n            predicted = predicted.to(\"cpu\")\n            y_true.extend(labels)\n            y_pred.extend(predicted)\n            pbar.update(loader.batch_size)\n    print(len(y_true), len(y_pred))\n    f1 = f1_score(y_true, y_pred, average = \"weighted\")\n    accuracy = accuracy_score(y_true, y_pred)\n    print(f\"F1-score: {f1 : 0.2f}\")\n    print(f\"Accuracy: {accuracy * 100 : 0.2f}%\")\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-05-15T01:00:01.591763Z","iopub.execute_input":"2024-05-15T01:00:01.592648Z","iopub.status.idle":"2024-05-15T01:00:01.600885Z","shell.execute_reply.started":"2024-05-15T01:00:01.592614Z","shell.execute_reply":"2024-05-15T01:00:01.599987Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"y_pred = evaluate_model(model, validation_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T01:00:02.624142Z","iopub.execute_input":"2024-05-15T01:00:02.624527Z","iopub.status.idle":"2024-05-15T01:03:05.022899Z","shell.execute_reply.started":"2024-05-15T01:00:02.624496Z","shell.execute_reply":"2024-05-15T01:03:05.021870Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Processing batches: 9488it [03:01, 52.33it/s]                          \n","output_type":"stream"},{"name":"stdout","text":"9485 9485\nF1-score:  0.11\nAccuracy:  19.33%\n","output_type":"stream"}]},{"cell_type":"code","source":"label_dict = dict()\nfor label in y_pred:\n    if label.item() in label_dict:\n        label_dict[label.item()] += 1\n    else:\n        label_dict[label.item()] = 1\n    \nfor label in label_dict.keys():\n    print(f\"{labelEncoder.inverse_transform([label])} : {label_dict[label]}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T01:06:34.410383Z","iopub.execute_input":"2024-05-15T01:06:34.411126Z","iopub.status.idle":"2024-05-15T01:06:34.440720Z","shell.execute_reply.started":"2024-05-15T01:06:34.411093Z","shell.execute_reply":"2024-05-15T01:06:34.439824Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"['no'] : 4912\n['yes'] : 4571\n['surfing'] : 2\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}