{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Todo\n\n- [ ] training loop\n- [ ] metrics computation\n- [ ] tensorboard/wandb","metadata":{}},{"cell_type":"code","source":"import datasets\nfrom transformers import AutoImageProcessor, AutoModel, AutoTokenizer\nfrom huggingface_hub import login\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\n\nimport math\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom dataclasses import dataclass","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:07:37.098168Z","iopub.execute_input":"2024-05-12T17:07:37.098619Z","iopub.status.idle":"2024-05-12T17:07:55.267253Z","shell.execute_reply.started":"2024-05-12T17:07:37.098591Z","shell.execute_reply":"2024-05-12T17:07:55.266304Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-12 17:07:45.983321: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-12 17:07:45.983443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-12 17:07:46.119669: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"login()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:08:06.315245Z","iopub.execute_input":"2024-05-12T17:08:06.316274Z","iopub.status.idle":"2024-05-12T17:08:06.338927Z","shell.execute_reply.started":"2024-05-12T17:08:06.316239Z","shell.execute_reply":"2024-05-12T17:08:06.337909Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fcc1b5490064c7693ea40f002fe35ce"}},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:08:19.055022Z","iopub.execute_input":"2024-05-12T17:08:19.055395Z","iopub.status.idle":"2024-05-12T17:08:19.084807Z","shell.execute_reply.started":"2024-05-12T17:08:19.055366Z","shell.execute_reply":"2024-05-12T17:08:19.083835Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"dataset = datasets.load_dataset(\"Gapes21/vqa2\", split = \"train\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:08:20.294159Z","iopub.execute_input":"2024-05-12T17:08:20.294501Z","iopub.status.idle":"2024-05-12T17:09:21.595464Z","shell.execute_reply.started":"2024-05-12T17:08:20.294477Z","shell.execute_reply":"2024-05-12T17:09:21.594558Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/361 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce38c5741064bc3aef9cc2a36e20fd6"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 487M/487M [00:02<00:00, 241MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:01<00:00, 258MB/s]  \nDownloading data: 100%|██████████| 487M/487M [00:01<00:00, 263MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 234MB/s]  \nDownloading data: 100%|██████████| 486M/486M [00:02<00:00, 213MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 233MB/s]  \nDownloading data: 100%|██████████| 485M/485M [00:02<00:00, 228MB/s]  \nDownloading data: 100%|██████████| 485M/485M [00:02<00:00, 237MB/s]  \nDownloading data: 100%|██████████| 487M/487M [00:02<00:00, 216MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 237MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 235MB/s]  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/109485 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11e0d2255514741829a4113a9a7ab3e"}},"metadata":{}}]},{"cell_type":"code","source":"labelEncoder = LabelEncoder()\nlabelEncoder.fit(dataset['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:26.073559Z","iopub.execute_input":"2024-05-12T17:09:26.074242Z","iopub.status.idle":"2024-05-12T17:09:26.373551Z","shell.execute_reply.started":"2024-05-12T17:09:26.074212Z","shell.execute_reply":"2024-05-12T17:09:26.372622Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"BERT = \"FacebookAI/roberta-base\"\nVIT = 'facebook/dinov2-base'","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:27.392972Z","iopub.execute_input":"2024-05-12T17:09:27.393335Z","iopub.status.idle":"2024-05-12T17:09:27.397847Z","shell.execute_reply.started":"2024-05-12T17:09:27.393307Z","shell.execute_reply":"2024-05-12T17:09:27.396802Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(VIT)\ntokenizer = AutoTokenizer.from_pretrained(BERT)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:28.280767Z","iopub.execute_input":"2024-05-12T17:09:28.281947Z","iopub.status.idle":"2024-05-12T17:09:30.236566Z","shell.execute_reply.started":"2024-05-12T17:09:28.281901Z","shell.execute_reply":"2024-05-12T17:09:30.235746Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8880a145540f4338a24d521496ba4e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55e614c6fa643fd81a629789b703755"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d42f801041a46d5a08ed3a465e5923f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b3bd353241a4c17a67f80efa59f6b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7bd3688904b44f3a9e9b1a0cf215680"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c61d3ab51e04eb496281ef11c010124"}},"metadata":{}}]},{"cell_type":"code","source":"class SastaLoader:\n    def __init__(self, dataset, batch_size, collator_fn):\n        self.dataset = dataset.shuffle()\n        self.collator_fn = collator_fn\n        self.len = len(self.dataset)\n        self.batch_size = batch_size\n        self.index = 0\n\n    def hasNext(self):\n        return self.index + self.batch_size <= self.len\n    \n    def reset(self):\n        self.index = 0\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index >= self.len:\n            raise StopIteration\n        batch = self.dataset[self.index: self.index + self.batch_size]\n        batch = self.collator_fn(batch)\n        self.index += self.batch_size\n        return batch\n    \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:30.998682Z","iopub.execute_input":"2024-05-12T17:09:30.999053Z","iopub.status.idle":"2024-05-12T17:09:31.007485Z","shell.execute_reply.started":"2024-05-12T17:09:30.999025Z","shell.execute_reply":"2024-05-12T17:09:31.006432Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def sasta_collator(batch):\n    # process images\n    images = processor(images = batch['image'], return_tensors=\"pt\")['pixel_values']\n\n    # preprocess questions\n    questions = tokenizer(\n            text=batch['question'],\n            padding='longest',\n            max_length=24,\n            truncation=True,\n            return_tensors='pt',\n            return_attention_mask=True,\n        )\n\n    # process labels\n    labels = torch.Tensor(labelEncoder.transform(batch['answer']))\n\n    return (images, questions, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:31.781518Z","iopub.execute_input":"2024-05-12T17:09:31.782343Z","iopub.status.idle":"2024-05-12T17:09:34.519763Z","shell.execute_reply.started":"2024-05-12T17:09:31.782306Z","shell.execute_reply":"2024-05-12T17:09:34.518750Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class VQAModel(nn.Module):\n    def __init__(\n        self,\n        num_labels,\n        intermediate_dim,\n        pretrained_text_name,\n        pretrained_image_name\n    ):\n        super(VQAModel, self).__init__()\n        \n        self.num_labels = num_labels\n        self.intermediate_dim = intermediate_dim\n        self.pretrained_text_name = pretrained_text_name\n        self.pretrained_image_name = pretrained_image_name\n        \n        # Text and image encoders\n        \n        self.text_encoder = AutoModel.from_pretrained(self.pretrained_text_name)\n        self.image_encoder = AutoModel.from_pretrained(self.pretrained_image_name)\n\n        assert(self.text_encoder.config.hidden_size == self.image_encoder.config.hidden_size)\n\n        self.embedd_dim = self.text_encoder.config.hidden_size\n\n        # Cross attentions\n        self.textq = nn.MultiheadAttention(self.embedd_dim, 1, 0.1, batch_first=True)\n        self.imgq = nn.MultiheadAttention(self.embedd_dim, 1, 0.1, batch_first=True)\n        \n        # Classifier\n        self.classifier = nn.Linear(self.embedd_dim, self.num_labels)\n\n    def forward(\n        self,\n        input_ids,\n        pixel_values,\n        attention_mask\n    ):\n        # Encode text with masking\n        encoded_text = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        \n        # Encode images\n        encoded_image = self.image_encoder(\n            pixel_values=pixel_values,\n        )\n        \n        text = encoded_text.last_hidden_state\n        img = encoded_image.last_hidden_state\n\n        textcls = self.textq(text, img, img)[0][:, 0, :]\n        imgcls = self.imgq(img, text, text)[0][:, 0, :]\n\n        cls = textcls+imgcls\n        \n        # Make predictions\n        logits = self.classifier(cls)\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:34.521265Z","iopub.execute_input":"2024-05-12T17:09:34.521594Z","iopub.status.idle":"2024-05-12T17:09:34.535595Z","shell.execute_reply.started":"2024-05-12T17:09:34.521568Z","shell.execute_reply":"2024-05-12T17:09:34.534755Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"#### Model, optimizer and loss","metadata":{}},{"cell_type":"code","source":"def save_model(model, name):\n    torch.save(model.state_dict(), name)\n\ndef initVQA():\n    model = VQAModel(len(labelEncoder.classes_), 512, BERT, VIT).to(device)\n    return model\n\ndef load_model(name, backup = initVQA):\n    model = backup()\n    try : \n        model.load_state_dict(torch.load(f\"/kaggle/working/{name}\"))\n        print(\"Loaded model successfully.\")\n    except:\n        print(\"Couldn't find model. Initializing from scratch.\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:34.537113Z","iopub.execute_input":"2024-05-12T17:09:34.537593Z","iopub.status.idle":"2024-05-12T17:09:34.548898Z","shell.execute_reply.started":"2024-05-12T17:09:34.537562Z","shell.execute_reply":"2024-05-12T17:09:34.548143Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"vqa_dr.pth\")\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:09:35.720256Z","iopub.execute_input":"2024-05-12T17:09:35.720724Z","iopub.status.idle":"2024-05-12T17:09:48.084337Z","shell.execute_reply.started":"2024-05-12T17:09:35.720686Z","shell.execute_reply":"2024-05-12T17:09:48.083397Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaab114f6b2c4a3991be62c2361e6889"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/548 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3b5e4703924fbe880f1de0a69e3330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001946b66f0b4766b43ad93b50d93259"}},"metadata":{}},{"name":"stdout","text":"Loaded model successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Hyperparams","metadata":{}},{"cell_type":"code","source":"collator_fn = sasta_collator\nloader = SastaLoader(dataset, 16, sasta_collator)\nnum_epochs = 2","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:10:11.698636Z","iopub.execute_input":"2024-05-12T17:10:11.699525Z","iopub.status.idle":"2024-05-12T17:10:11.758165Z","shell.execute_reply.started":"2024-05-12T17:10:11.699488Z","shell.execute_reply":"2024-05-12T17:10:11.757255Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, criterion, loader, num_epochs, device):\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n    loss_plot, accuracy_plot = [], []\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        correct = 0\n        total_samples = 0\n        with tqdm(total=len(loader), desc=\"Processing batches\", dynamic_ncols=True) as pbar:\n            for batchidx, batch in enumerate(loader):\n                ids = batch[1]['input_ids'].to(device)\n                pxlvalues = batch[0].to(device)\n                masks = batch[1]['attention_mask'].to(device)\n                labels = batch[2].to(device)\n\n                optimizer.zero_grad()\n                outputs = model(ids, pxlvalues, masks)\n                loss = criterion(outputs, labels.long())\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item() * loader.batch_size\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n                pbar.update(loader.batch_size)\n                if batchidx % 16000 <= 1:\n                    save_model(model, 'vqa_dr.pth')\n                \n        epoch_loss = total_loss / total_samples\n        accuracy = correct / total_samples\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n        accuracy_plot.append(accuracy * 100)\n        loss_plot.append(epoch_loss)\n        save_model(model, \"vqa_dr.pth\")\n        scheduler.step()\n        loader.reset()\n    plt.plot(accuracy_plot)\n    plt.plot(loss_plot)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:10:24.548189Z","iopub.execute_input":"2024-05-12T17:10:24.548572Z","iopub.status.idle":"2024-05-12T17:10:24.560481Z","shell.execute_reply.started":"2024-05-12T17:10:24.548542Z","shell.execute_reply":"2024-05-12T17:10:24.559375Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train(model, optimizer, criterion, loader, num_epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:10:29.103786Z","iopub.execute_input":"2024-05-12T17:10:29.104111Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Processing batches: 100%|█████████▉| 109472/109485 [1:09:54<00:00, 26.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2, Loss: 5.5683, Accuracy: 0.1905\n","output_type":"stream"},{"name":"stderr","text":"Processing batches:  54%|█████▍    | 58896/109485 [37:41<32:31, 25.92it/s]  ","output_type":"stream"}]},{"cell_type":"code","source":"save_model(model, \"vqr_dr2.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}