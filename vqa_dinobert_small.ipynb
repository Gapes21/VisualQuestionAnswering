{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8439974,"sourceType":"datasetVersion","datasetId":5027732}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import datasets\nfrom transformers import AutoImageProcessor, AutoModel, AutoTokenizer\nfrom huggingface_hub import login\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\n\nimport math\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score, accuracy_score\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport os\n\nfrom dataclasses import dataclass","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:50:41.954580Z","iopub.execute_input":"2024-05-17T11:50:41.954975Z","iopub.status.idle":"2024-05-17T11:50:41.961695Z","shell.execute_reply.started":"2024-05-17T11:50:41.954943Z","shell.execute_reply":"2024-05-17T11:50:41.960772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"login(\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:50:43.034965Z","iopub.execute_input":"2024-05-17T11:50:43.035315Z","iopub.status.idle":"2024-05-17T11:50:43.202686Z","shell.execute_reply.started":"2024-05-17T11:50:43.035287Z","shell.execute_reply":"2024-05-17T11:50:43.201798Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:50:45.461104Z","iopub.execute_input":"2024-05-17T11:50:45.461695Z","iopub.status.idle":"2024-05-17T11:50:45.490389Z","shell.execute_reply.started":"2024-05-17T11:50:45.461667Z","shell.execute_reply":"2024-05-17T11:50:45.489489Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"dataset = datasets.load_dataset(\"Gapes21/vqa2\", split = \"train\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:50:47.291257Z","iopub.execute_input":"2024-05-17T11:50:47.292205Z","iopub.status.idle":"2024-05-17T11:52:00.523884Z","shell.execute_reply.started":"2024-05-17T11:50:47.292172Z","shell.execute_reply":"2024-05-17T11:52:00.522671Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/361 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf69347849e479db42d0a974b850e29"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 487M/487M [00:02<00:00, 220MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:09<00:00, 50.1MB/s] \nDownloading data: 100%|██████████| 487M/487M [00:02<00:00, 220MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 238MB/s]  \nDownloading data: 100%|██████████| 486M/486M [00:06<00:00, 78.1MB/s] \nDownloading data: 100%|██████████| 490M/490M [00:06<00:00, 79.7MB/s] \nDownloading data: 100%|██████████| 485M/485M [00:06<00:00, 75.8MB/s] \nDownloading data: 100%|██████████| 485M/485M [00:02<00:00, 233MB/s]  \nDownloading data: 100%|██████████| 487M/487M [00:02<00:00, 232MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 221MB/s]  \nDownloading data: 100%|██████████| 490M/490M [00:02<00:00, 200MB/s]  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/109485 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd2880c3f74423984de44227cafef08"}},"metadata":{}}]},{"cell_type":"code","source":"labelEncoder = LabelEncoder()\nlabelEncoder.fit(dataset['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:07.404475Z","iopub.execute_input":"2024-05-17T11:52:07.405503Z","iopub.status.idle":"2024-05-17T11:52:07.737481Z","shell.execute_reply.started":"2024-05-17T11:52:07.405468Z","shell.execute_reply":"2024-05-17T11:52:07.736558Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"labelMap = {}\nfor i, label in enumerate(labelEncoder.classes_):\n    labelMap[label] = i\nclass_counts = [0 for i in range(len(labelMap))]\nfor label in tqdm(dataset[\"answer\"]):\n    labelid = labelMap[label]\n    class_counts[labelid] += 1\ntotal_samples = sum(class_counts)\nclass_weights = [total_samples / (len(class_counts) * count) for count in class_counts]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:08.148395Z","iopub.execute_input":"2024-05-17T11:52:08.148737Z","iopub.status.idle":"2024-05-17T11:52:15.624461Z","shell.execute_reply.started":"2024-05-17T11:52:08.148709Z","shell.execute_reply":"2024-05-17T11:52:15.623592Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 109485/109485 [00:00<00:00, 1014112.30it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"BERT = \"smallbenchnlp/roberta-small\"\nVIT = 'facebook/dinov2-small'","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:15.626461Z","iopub.execute_input":"2024-05-17T11:52:15.627270Z","iopub.status.idle":"2024-05-17T11:52:15.973515Z","shell.execute_reply.started":"2024-05-17T11:52:15.627235Z","shell.execute_reply":"2024-05-17T11:52:15.972254Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(VIT)\ntokenizer = AutoTokenizer.from_pretrained(BERT)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:15.975109Z","iopub.execute_input":"2024-05-17T11:52:15.976562Z","iopub.status.idle":"2024-05-17T11:52:18.006897Z","shell.execute_reply.started":"2024-05-17T11:52:15.976523Z","shell.execute_reply":"2024-05-17T11:52:18.006074Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939f1147cc8945b09d20c07a3e2eb496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/327 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d4fe5d0cead4ec79c20f20276fe37e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9971a8b152494e77ac7f8f1a93abd876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7895731d337f465c99ffc964fc9adcc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24971c779954f3581cb79421510a0d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73242cfaacad4bb580787885af637533"}},"metadata":{}}]},{"cell_type":"code","source":"class SastaLoader:\n    def __init__(self, dataset, batch_size, collator_fn, train_max = 100000, mode = \"train\"):\n        self.dataset = dataset.shuffle()\n        self.collator_fn = collator_fn\n        self.len = len(self.dataset)\n        self.batch_size = batch_size\n        if mode == \"train\":\n            self.index = 0\n        else :\n            self.index = train_max\n        self.train_max = train_max\n        self.mode = mode\n\n    def hasNext(self):\n        if self.mode == \"train\":\n            return self.index + self.batch_size <= self.train_max\n        else :\n            return self.index + self.batch.size <= self.len\n    \n    def reset(self):\n        if self.mode == \"train\":\n            self.index = 0\n        else:\n            self.index = self.train_max\n        \n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.mode == \"train\":\n            if self.index >= self.train_max:\n                raise StopIteration\n        else :\n            if self.index >= self.len:\n                raise StopIteration\n                \n        batch = self.dataset[self.index: self.index + self.batch_size]\n        batch = self.collator_fn(batch)\n        self.index += self.batch_size\n        return batch\n    \n    def __len__(self):\n        if self.mode == \"train\":\n            return self.train_max\n        return self.len - self.train_max\n    \n    def train(self):\n        self.mode = \"train\"\n        \n    def validate(self):\n        self.mode = \"validation\"","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:24.702342Z","iopub.execute_input":"2024-05-17T11:52:24.702715Z","iopub.status.idle":"2024-05-17T11:52:24.715336Z","shell.execute_reply.started":"2024-05-17T11:52:24.702685Z","shell.execute_reply":"2024-05-17T11:52:24.714180Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def sasta_collator(batch):\n    # process images\n    images = processor(images = batch['image'], return_tensors=\"pt\")['pixel_values']\n\n    # preprocess questions\n    questions = tokenizer(\n            text=batch['question'],\n            padding='longest',\n            max_length=24,\n            truncation=True,\n            return_tensors='pt',\n            return_attention_mask=True,\n        )\n\n    # process labels\n    labels = torch.Tensor(labelEncoder.transform(batch['answer']))\n    return (images, questions, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:30.773935Z","iopub.execute_input":"2024-05-17T11:52:30.774537Z","iopub.status.idle":"2024-05-17T11:52:30.780705Z","shell.execute_reply.started":"2024-05-17T11:52:30.774503Z","shell.execute_reply":"2024-05-17T11:52:30.779632Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class DinoBertSmall(nn.Module):\n    def __init__(\n        self,\n        num_labels,\n        intermediate_dim,\n        pretrained_text_name,\n        pretrained_image_name,\n        classifier_dim = 9024,\n    ):\n        super(DinoBertSmall, self).__init__()\n        \n        self.num_labels = num_labels\n        self.intermediate_dim = intermediate_dim\n        self.pretrained_text_name = pretrained_text_name\n        self.pretrained_image_name = pretrained_image_name\n        self.classifier_dim = classifier_dim\n        \n        # Text and image encoders\n        \n        self.text_encoder = AutoModel.from_pretrained(self.pretrained_text_name)\n        self.image_encoder = AutoModel.from_pretrained(self.pretrained_image_name)\n\n#         assert(self.text_encoder.config.hidden_size == self.image_encoder.config.hidden_size)\n\n        self.embedd_dim_text = self.text_encoder.config.hidden_size\n        self.embedd_dim_img = self.image_encoder.config.hidden_size\n\n        print(self.embedd_dim_text, self.embedd_dim_img)\n\n        # Classifier\n        self.initdim = self.embedd_dim_img + self.embedd_dim_text\n        self.classifier = nn.Sequential(\n            nn.Linear(self.initdim, self.num_labels),\n            nn.LeakyReLU(), \n            nn.Dropout(p = 0.1),\n            nn.Linear(self.num_labels, self.num_labels)\n        )\n\n    def forward(\n        self,\n        input_ids,\n        pixel_values,\n        attention_mask\n    ):\n        # Encode text with masking\n        encoded_text = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        \n        # Encode images\n        encoded_image = self.image_encoder(\n            pixel_values=pixel_values,\n        )\n        \n        text = encoded_text.last_hidden_state\n        img = encoded_image.last_hidden_state\n        \n        conatt = torch.cat((text[:, 0, :], img[:, 0, :]), dim = 1)\n        conatt = conatt.view(conatt.shape[0], -1)\n        \n        # Make predictions\n        logits = self.classifier(conatt)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:34.351376Z","iopub.execute_input":"2024-05-17T11:52:34.352261Z","iopub.status.idle":"2024-05-17T11:52:34.363941Z","shell.execute_reply.started":"2024-05-17T11:52:34.352225Z","shell.execute_reply":"2024-05-17T11:52:34.363014Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def save_model(model, name):\n    torch.save(model.state_dict(), name)\n\ndef initVQA():\n    model = DinoBertSmall(len(labelEncoder.classes_), 512, BERT, VIT).to(device)\n    return model\n\ndef load_model(name, backup = initVQA, frommem = True):\n    model = backup()\n    if frommem == False:\n        print(\"Initializing from scratch.\")\n        return model\n    try : \n        model.load_state_dict(torch.load(f\"{name}\"))\n        print(\"Loaded model successfully.\")\n    except:\n        print(\"Couldn't find model. Initializing from scratch.\")\n    return model\n\ndef print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:22:13.833330Z","iopub.execute_input":"2024-05-17T12:22:13.833707Z","iopub.status.idle":"2024-05-17T12:22:13.842396Z","shell.execute_reply.started":"2024-05-17T12:22:13.833660Z","shell.execute_reply":"2024-05-17T12:22:13.841316Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Testing the model and tweaking it","metadata":{}},{"cell_type":"code","source":"# collator_fn = sasta_collator\n# loader = SastaLoader(dataset, 1, sasta_collator)\n# model = load_model(\"vqa_dr.pth\", frommem = False)\n\n# ids, pxlvalues, masks, labels = None, None, None, None\n# for batchid, batch in enumerate(loader):\n#     ids = batch[1]['input_ids'].to(device)\n#     pxlvalues = batch[0].to(device)\n#     masks = batch[1]['attention_mask'].to(device)\n#     labels = batch[2].to(device)\n#     break\n# len(ids), len(pxlvalues), len(masks), len(labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:39.516170Z","iopub.execute_input":"2024-05-17T11:52:39.516519Z","iopub.status.idle":"2024-05-17T11:52:39.520920Z","shell.execute_reply.started":"2024-05-17T11:52:39.516490Z","shell.execute_reply":"2024-05-17T11:52:39.519908Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# outputs = model(ids, pxlvalues, masks)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:52:40.883397Z","iopub.execute_input":"2024-05-17T11:52:40.884324Z","iopub.status.idle":"2024-05-17T11:52:40.888274Z","shell.execute_reply.started":"2024-05-17T11:52:40.884291Z","shell.execute_reply":"2024-05-17T11:52:40.887143Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"#### Model, optimizer and loss","metadata":{}},{"cell_type":"code","source":"model = load_model(\"/kaggle/input/dinobert-small-models/dinobert_small_fully_trained.pth\", frommem = True)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:22:22.109731Z","iopub.execute_input":"2024-05-17T12:22:22.110556Z","iopub.status.idle":"2024-05-17T12:22:28.208266Z","shell.execute_reply.started":"2024-05-17T12:22:22.110524Z","shell.execute_reply":"2024-05-17T12:22:28.207370Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at smallbenchnlp/roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"256 384\nLoaded model successfully.\ntrainable params: 135352192 || all params: 135352192 || trainable%: 100.00\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Hyperparams","metadata":{}},{"cell_type":"code","source":"collator_fn = sasta_collator\nloader = SastaLoader(dataset, 64, sasta_collator)\nnum_epochs = 10\noptimizer = optim.Adam(model.parameters(), lr=5e-4)\ncriterion = nn.CrossEntropyLoss()\nscheduler = StepLR(optimizer, step_size=2, gamma=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T06:23:25.802956Z","iopub.execute_input":"2024-05-17T06:23:25.803346Z","iopub.status.idle":"2024-05-17T06:23:31.483838Z","shell.execute_reply.started":"2024-05-17T06:23:25.803310Z","shell.execute_reply":"2024-05-17T06:23:31.482877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, criterion, scheduler, loader, num_epochs, device):\n    loss_plot, accuracy_plot = [], []\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n        correct = 0\n        total_samples = 0\n        with tqdm(total=len(loader), desc=\"Processing batches\", dynamic_ncols=True) as pbar:\n            for batchidx, batch in enumerate(loader):\n                ids = batch[1]['input_ids'].to(device)\n                pxlvalues = batch[0].to(device)\n                masks = batch[1]['attention_mask'].to(device)\n                labels = batch[2].to(device)\n\n                optimizer.zero_grad()\n                outputs = model(ids, pxlvalues, masks)\n                loss = criterion(outputs, labels.long())\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item() * loader.batch_size\n                _, predicted = torch.max(outputs, 1)\n                correct += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n                pbar.update(loader.batch_size)\n                if batchidx % 16000 <= 1:\n                    save_model(model, 'vqa_dr.pth')\n                \n        epoch_loss = total_loss / total_samples\n        accuracy = correct / total_samples\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n        accuracy_plot.append(accuracy * 100)\n        loss_plot.append(epoch_loss)\n        save_model(model, \"vqa_dr.pth\")\n        scheduler.step()\n        loader.reset()\n    plt.plot(accuracy_plot)\n    plt.plot(loss_plot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model, optimizer, criterion, scheduler, loader, num_epochs, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_loader = SastaLoader(dataset, 16, sasta_collator, mode = \"validation\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:22:35.583487Z","iopub.execute_input":"2024-05-17T12:22:35.584055Z","iopub.status.idle":"2024-05-17T12:22:35.645455Z","shell.execute_reply.started":"2024-05-17T12:22:35.584025Z","shell.execute_reply":"2024-05-17T12:22:35.644691Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, loader, device):\n    y_true, y_pred = [], []\n    model.eval()\n#     loader.reset()\n    with tqdm(total=len(loader), desc=\"Processing batches\", dynamic_ncols=True) as pbar:\n        for batchidx, batch in enumerate(loader):\n            ids = batch[1]['input_ids'].to(device)\n            pxlvalues = batch[0].to(device)\n            masks = batch[1]['attention_mask'].to(device)\n            labels = batch[2].to(\"cpu\")\n            outputs = model(ids, pxlvalues, masks)\n            _, predicted = torch.max(outputs, 1)\n            predicted = predicted.to(\"cpu\")\n            y_true.extend(labels)\n            y_pred.extend(predicted)\n            pbar.update(loader.batch_size)\n    f1 = f1_score(y_true, y_pred, average = \"weighted\")\n    accuracy = accuracy_score(y_true, y_pred)\n    print(f\"F1-score: {f1 : 0.2f}\")\n    print(f\"Accuracy: {accuracy * 100 : 0.2f}%\")\n    return y_pred, y_true","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:22:36.766655Z","iopub.execute_input":"2024-05-17T12:22:36.767380Z","iopub.status.idle":"2024-05-17T12:22:36.775655Z","shell.execute_reply.started":"2024-05-17T12:22:36.767346Z","shell.execute_reply":"2024-05-17T12:22:36.774594Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"y_pred, y_true = evaluate_model(model, validation_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:22:37.738768Z","iopub.execute_input":"2024-05-17T12:22:37.739791Z","iopub.status.idle":"2024-05-17T12:24:52.037154Z","shell.execute_reply.started":"2024-05-17T12:22:37.739757Z","shell.execute_reply":"2024-05-17T12:24:52.036130Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Processing batches: 9488it [02:13, 71.17it/s]                          \n","output_type":"stream"},{"name":"stdout","text":"F1-score:  0.10\nAccuracy:  19.14%\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:36:09.338535Z","iopub.execute_input":"2024-05-17T12:36:09.339216Z","iopub.status.idle":"2024-05-17T12:36:09.343186Z","shell.execute_reply.started":"2024-05-17T12:36:09.339183Z","shell.execute_reply":"2024-05-17T12:36:09.342104Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"label_dict = dict()\nfor label in y_pred:\n    if label.item() in label_dict:\n        label_dict[label.item()] += 1\n    else:\n        label_dict[label.item()] = 1\n    \nfor label in label_dict.keys():\n    print(f\"{labelEncoder.inverse_transform([label])} : {label_dict[label]}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T12:30:45.297393Z","iopub.execute_input":"2024-05-17T12:30:45.298065Z","iopub.status.idle":"2024-05-17T12:30:45.321689Z","shell.execute_reply.started":"2024-05-17T12:30:45.298032Z","shell.execute_reply":"2024-05-17T12:30:45.320886Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['yes'] : 6714\n['no'] : 2771\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}